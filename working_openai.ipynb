{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 4966565,
     "sourceType": "datasetVersion",
     "datasetId": 2880535
    },
    {
     "sourceId": 7239614,
     "sourceType": "datasetVersion",
     "datasetId": 4192950
    },
    {
     "sourceId": 4298,
     "sourceType": "modelInstanceVersion",
     "modelInstanceId": 3093
    }
   ],
   "dockerImageVersionId": 30559,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T03:22:47.923259Z",
     "start_time": "2024-05-15T03:22:47.291003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import docx\n",
    "import base64\n",
    "import os\n",
    "import openai"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "INPUT_CTX_PATH = \"input/ctx\"\n",
    "FEATURE_PATH = \"input/feature\"\n",
    "OUTPUT_PATH = \"output\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T03:22:48.490519Z",
     "start_time": "2024-05-15T03:22:48.486894Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "def handledocx(filepath):\n",
    "    doc = docx.Document(filepath)\n",
    "    fullText = []\n",
    "    for para in doc.paragraphs:\n",
    "        fullText.append(para.text)\n",
    "    resp = {\n",
    "      \"type\": \"text\",\n",
    "      \"text\": '\\n'.join(fullText)\n",
    "    }\n",
    "    return resp\n",
    "\n",
    "\n",
    "def handlepng(filepath):\n",
    "\n",
    "    with open(filepath, \"rb\") as image_file:\n",
    "         base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "    resp =   {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          }\n",
    "    }\n",
    "    return resp\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T03:23:59.403071Z",
     "start_time": "2024-05-15T03:23:59.399142Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# print(os.listdir(INPUT_PATH))\n",
    "supported_files = {\n",
    "    \"png\": handlepng,\n",
    "    # \"pdf\": \"handlepdf\",\n",
    "    \"docx\": handledocx,\n",
    "    # \"txt\": \"handle txt\",\n",
    "}\n",
    "\n",
    "\n",
    "def getcontent(path):\n",
    "    content = []\n",
    "    input_files = [f for f in os.listdir(path) if os.path.isfile(f'{path}/{f}')]\n",
    "    \n",
    "    for i in input_files:\n",
    "    \n",
    "        ext = i.split(\".\")[-1]\n",
    "        try:\n",
    "            inp = supported_files[ext](f'{path}/{i}')\n",
    "            content.append(inp)\n",
    "        except Exception as e:\n",
    "            print(f\"unsupported file type, {i}, {e}\")\n",
    "    return content\n",
    "\n",
    "def promptobj(prompt):\n",
    "    return {\n",
    "      \"type\": \"text\",\n",
    "      \"text\": prompt\n",
    "    }\n",
    "\n",
    "pre_prompt = promptobj(\"You are a product tester who will write test cases for the following project.\")\n",
    "\n",
    "ctx_content = getcontent(INPUT_CTX_PATH)\n",
    "\n",
    "mid_prompt = promptobj(\"For the above product we are building a new feature with the below description.\")\n",
    "\n",
    "feature_content = getcontent(FEATURE_PATH)\n",
    "\n",
    "end_prompt = promptobj(\"Generate 50 test cases for this new feature of the format, (test_case_name, test_case_description) for this products. Do not say anything else. Only provide csv compatible text output. and do not generate less than 50 test cases\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T03:24:00.759328Z",
     "start_time": "2024-05-15T03:24:00.732524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupported file type, RoadTrip.pdf, 'pdf'\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T03:24:14.461574Z",
     "start_time": "2024-05-15T03:24:14.459342Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "# OpenAI API Key\n",
    "with open(\"secrets.txt\",\"r\") as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"path_to_your_image.jpg\"\n",
    "\n",
    "\n",
    "\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "payload = {\n",
    "  \"model\": \"gpt-4-vision-preview\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [pre_prompt,*ctx_content, mid_prompt, *feature_content, end_prompt]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 3000\n",
    "}\n",
    "\n",
    "# print(payload)\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "print(response.json())\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T03:25:22.550434Z",
     "start_time": "2024-05-15T03:24:29.361121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-9OzXoBZEPyUJX39CM08C3J0lXyRSy', 'object': 'chat.completion', 'created': 1715743476, 'model': 'gpt-4-1106-vision-preview', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"test_case_name,test_case_description\\nVR_Scenario_Selection_001,Verify that the VR environment correctly loads a pre-designed scenario.\\nVR_Scenario_Selection_002,Verify that the user can scroll through and select from a list of scenarios.\\nVR_Scenario_Selection_003,Validate that the VR environment displays an error when an invalid scenario is selected.\\nVR_Scenario_Selection_004,Verify custom scenario creation with valid recorded dialogue.\\nVR_Scenario_Selection_005,Test loading times for scenario selection on various devices.\\nVR_Environment_Visuals_001,Ensure that visuals match the selected scenario (coffee shop, airport, etc.).\\nVR_Environment_Visuals_002,Verify visual quality and resolution in the VR environment.\\nVR_Environment_Visuals_003,Check for visual glitches or artifacts within the environment.\\nVR_Environment_Sounds_001,Confirm that ambient sounds are appropriate for the selected scenario.\\nVR_Environment_Sounds_002,Verify volume control of ambient sounds within the VR environment.\\nVR_AI_Conversation_001,Test AI conversation partner's response accuracy to predefined inputs.\\nVR_AI_Conversation_002,Verify AI conversation partner's adaptability to changing user skill levels.\\nVR_AI_Conversation_003,Ensure that the AI conversation partner can handle unexpected user inputs.\\nVR_AI_Conversation_004,Measure response time of AI conversation partner.\\nVR_AI_Conversation_005,Check for natural conversational flow with AI, including pauses and interjections.\\nFeedback_Mechanism_RealTime_001,Validate visual cues for pronunciation errors during conversations.\\nFeedback_Mechanism_RealTime_002,Confirm audio cues are audible and clear for grammatical mistakes.\\nFeedback_Mechanism_RealTime_003,Test for the timing and accuracy of real-time feedback during dialogues.\\nFeedback_Mechanism_Summary_001,Review post-scenario summary for comprehensive feedback.\\nFeedback_Mechanism_Summary_002,Verify that the report highlights user's strengths and weaknesses accurately.\\nVR_Headset_Compatibility_001,Ensure feature works with Oculus Quest headset.\\nVR_Headset_Compatibility_002,Test compatibility with HTC Vive.\\nVR_Headset_Compatibility_003,Check feature performance on different VR headset models.\\nSpeech_Recognition_Accuracy_001,Verify speech recognition efficiency with various accents.\\nSpeech_Recognition_Accuracy_002,Test speech recognition in noisy environments.\\nNLP_Module_Efficiency_001,Check for correct grammatical analysis in NLP engine.\\nNLP_Module_Efficiency_002,Verify vocabulary suggestions are relevant and diverse.\\nScenario_Creation_Tools_001,Ensure usability of scenario creation tools for non-technical users.\\nScenario_Creation_Tools_002,Test importing functionality for custom scenarios with recorded dialogues.\\nProgress_Tracking_001,Verify accurate tracking of conversational accuracy metrics.\\nProgress_Tracking_002,Check the progress report for vocabulary acquisition over time.\\nProgress_Tracking_003,Validate fluency score calculations with varied user data.\\nIntegration_Main_App_001,Test seamless integration with the existing language learning app.\\nIntegration_Main_App_002,Confirm data synchronization between the main app and VR feature.\\nCustom_Scenario_Advanced_001,Test advanced custom scenario creation with multiple dialogues.\\nCustom_Scenario_Advanced_002,Check if scenarios can integrate with real-world current events.\\nVR_Environment_Control_001,Ensure user has control over VR environment settings.\\nVR_Environment_Control_002,Test user ability to customize environmental factors (time of day, weather).\\nAI_Conversation_NonVerbal_001,Test AI's ability to include non-verbal cues in conversation.\\nAI_Conversation_NonVerbal_002,Validate AI behavior with user's non-verbal inputs in advanced development.\\nVR_Environment_Loading_001,Measure loading time for scenarios on base level hardware.\\nVR_Environment_Loading_002,Confirm loading time is within acceptable limits on high-end devices.\\nUser_Experience_Design_001,Ensure user interface is intuitive and easy to navigate.\\nUser_Experience_Design_002,Test user feedback on clarity of instructions within the VR environment.\\nEarly_Release_Limitations_001,Check user understanding of initial release's core scenario limitations.\\nEarly_Release_Limitations_002,Verify adequate user communication regarding future feature expansions.\\nSpeech_Recognition_Dialects_001,Test for speech recognition accuracy across various English dialects.\\nSpeech_Recognition_Dialects_002,Benchmark speech recognition performance for non-native speakers.\\nFeedback_Mechanism_Details_001,Confirm that the feedback mechanism addresses specific language details.\\nFeedback_Mechanism_Details_002,Test if the feedback provides constructive and actionable advice.\\nMonetization_Strategy_001,Prepare test cases for potential in-app purchases within the VR feature.\\nMonetization_Strategy_002,Validate user acceptance of subscription models for full feature access.\\nSuccess_Metrics_Reporting_001,Check for accurate reporting features measuring user success metrics.\\nSuccess_Metrics_Reporting_002,Ensure comprehensive data visualization for user progress in reports.\"}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 3960, 'completion_tokens': 1035, 'total_tokens': 4995}, 'system_fingerprint': None}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "with open(f'{OUTPUT_PATH}/output1.csv', \"w+\") as f:\n",
    "    f.write(response.json()['choices'][0]['message']['content'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T03:25:31.891402Z",
     "start_time": "2024-05-15T03:25:31.886131Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
